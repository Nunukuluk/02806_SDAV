{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the code behind this notebook, press the button below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To hide the code when displayed in NB viewer 0 mybinder\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(null);\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      \n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      \n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from bokeh.models import ColumnDataSource, FactorRange\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show, output_notebook, output_file\n",
    "from bokeh.models import Legend\n",
    "import folium, bokeh, random, warnings\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split \n",
    "warnings.filterwarnings('ignore')\n",
    "from math import pi\n",
    "from bokeh.palettes import Category20c, GnBu\n",
    "from bokeh.transform import cumsum\n",
    "\n",
    "# Output notebook to display bokeh plots\n",
    "output_notebook(verbose=False, hide_banner=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Assignment B - Investigating New York City Crashes\n",
    "\n",
    "By Mariana Alves Monteiro (s193155), Nynne Kajs (s193156) & Piriya Sureshkumar (s184302)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With millions of people travelling every day, New York city faces a challenging traffic situation with a lot of traffic related accidents. In 2014 Mayor Bill de Blasio created a program called vision Zero pledging to eliminate traffic deaths by 2024 (Fitzsimmons, 2020). Among other things, the plan includes increased use of speed cameras, charges against traffic violators and quicker repair of traffic signals. Despite the efforts to eliminate traffic related deaths, last year in 2019, the number of pedestrians and cyclists killed in traffic was in fact larger than the years before. The trends from years 2013 till 2019 can be seen in the graph below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve \"Motor Vehicle Collisions - Crashes\" data\n",
    "url = 'https://data.cityofnewyork.us/api/views/h9gi-nx95/rows.csv?accessType=DOWNLOAD'\n",
    "df = pd.read_csv(url)\n",
    "df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE'])\n",
    "year = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe that holds the original dataframe df\n",
    "interval_data = df.copy()\n",
    "\n",
    "# The interval variable is used to set the new dates in the \n",
    "# interval_data DataFrame, so that only the ones with the data from the year\n",
    "# will be used.\n",
    "interval_data = interval_data[interval_data['CRASH DATE'].dt.year == year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to use for bokeh plots, containing number of pedestrians, \n",
    "# cyclists, and motorists injured or killed in different time series\n",
    "time_series_df = interval_data[['CRASH DATE', 'CRASH TIME','NUMBER OF PERSONS INJURED',\n",
    "       'NUMBER OF PERSONS KILLED', 'NUMBER OF PEDESTRIANS INJURED',\n",
    "       'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED',\n",
    "       'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED',\n",
    "       'NUMBER OF MOTORIST KILLED']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column to store hour of day\n",
    "time_series_df['HOUR OF DAY'] = pd.to_datetime(time_series_df['CRASH TIME']).dt.hour.copy()\n",
    "\n",
    "# Create column to store day of the week\n",
    "time_series_df['WEEKDAY'] = pd.to_datetime(time_series_df['CRASH DATE']).dt.dayofweek.copy()\n",
    "\n",
    "# Create column to store hour of the week\n",
    "time_series_df['HOUR OF WEEK'] = time_series_df['WEEKDAY'] * 24 + time_series_df['HOUR OF DAY']\n",
    "\n",
    "# Create column to store month \n",
    "time_series_df['MONTH'] = pd.to_datetime(time_series_df['CRASH DATE']).dt.month.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge number of injured and dead for pedestrians, persons, cyclists, and motorists\n",
    "time_series_df['TOTAL'] = time_series_df['NUMBER OF PERSONS INJURED'] + time_series_df['NUMBER OF PERSONS KILLED']\n",
    "time_series_df['PEDESTRIANS'] = time_series_df['NUMBER OF PEDESTRIANS INJURED'] + time_series_df['NUMBER OF PEDESTRIANS KILLED']\n",
    "time_series_df['CYCLISTS'] = time_series_df['NUMBER OF CYCLIST INJURED'] + time_series_df['NUMBER OF CYCLIST KILLED']\n",
    "time_series_df['MOTORISTS'] = time_series_df['NUMBER OF MOTORIST INJURED'] + time_series_df['NUMBER OF MOTORIST KILLED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop not needed columns and reset index after drop\n",
    "time_series_df = time_series_df.drop(['CRASH DATE', 'CRASH TIME', 'NUMBER OF PERSONS INJURED',\n",
    "       'NUMBER OF PERSONS KILLED', 'NUMBER OF PEDESTRIANS INJURED',\n",
    "       'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED',\n",
    "       'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED',\n",
    "       'NUMBER OF MOTORIST KILLED'], axis=1)\n",
    "\n",
    "time_series_df.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The TOTAL column is of type float, change to integer\n",
    "time_series_df['TOTAL'] = time_series_df['TOTAL'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list to hold names for accidents\n",
    "accident_types = list(time_series_df.columns[4:])\n",
    "\n",
    "# Make base dataframe to store data for plots\n",
    "base_data = pd.DataFrame(columns = list(accident_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe with data for all years based on original dataframe\n",
    "no_interval_df = df[['CRASH DATE', 'CRASH TIME', 'NUMBER OF PERSONS INJURED',\n",
    "       'NUMBER OF PERSONS KILLED', 'NUMBER OF PEDESTRIANS INJURED',\n",
    "       'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED',\n",
    "       'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED',\n",
    "       'NUMBER OF MOTORIST KILLED']].copy()\n",
    "\n",
    "# Drop NAN values and reset indices\n",
    "no_interval_df = no_interval_df.dropna()\n",
    "no_interval_df = no_interval_df.reset_index(drop=True)\n",
    "\n",
    "# Create column to store year\n",
    "no_interval_df['YEAR'] = pd.to_datetime(no_interval_df['CRASH DATE']).dt.year.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge number of injured and dead for pedestrians, persons, cyclists, and motorists\n",
    "no_interval_df['TOTAL'] = no_interval_df['NUMBER OF PERSONS INJURED'] + no_interval_df['NUMBER OF PERSONS KILLED']\n",
    "no_interval_df['PEDESTRIANS'] = no_interval_df['NUMBER OF PEDESTRIANS INJURED'] + no_interval_df['NUMBER OF PEDESTRIANS KILLED']\n",
    "no_interval_df['CYCLISTS'] = no_interval_df['NUMBER OF CYCLIST INJURED'] + no_interval_df['NUMBER OF CYCLIST KILLED']\n",
    "no_interval_df['MOTORISTS'] = no_interval_df['NUMBER OF MOTORIST INJURED'] + no_interval_df['NUMBER OF MOTORIST KILLED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop not needed columns and reset indices after drop\n",
    "no_interval_df = no_interval_df.drop(['CRASH DATE', 'CRASH TIME', 'NUMBER OF PERSONS INJURED',\n",
    "                                      'NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF CYCLIST INJURED', \n",
    "                                      'NUMBER OF MOTORIST INJURED'], \n",
    "                                     axis=1)\n",
    "no_interval_df.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The TOTAL and NUMBER OF PERSONS KILLED columns are of type float, change to integer\n",
    "no_interval_df['TOTAL'] = no_interval_df['TOTAL'].astype(int)\n",
    "no_interval_df['NUMBER OF PERSONS KILLED'] = no_interval_df['NUMBER OF PERSONS KILLED'].astype(int)\n",
    "\n",
    "# Rename columns; total becomes persons, motosist becomes motorists, and cyclist becomes cyclists\n",
    "no_interval_df.rename(columns={'NUMBER OF PERSONS KILLED':'NUMBER OF TOTAL KILLED',\n",
    "                               'NUMBER OF MOTORIST KILLED':'NUMBER OF MOTORISTS KILLED',\n",
    "                               'NUMBER OF CYCLIST KILLED':'NUMBER OF CYCLISTS KILLED'}, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes to store data to go into bokeh plots.\n",
    "# These dataframes are the ones that will be converted to b bokeh \n",
    "# ColumnDataSource\n",
    "\n",
    "# Hour of day\n",
    "hour_of_day_df = base_data.copy()\n",
    "unique_hours = time_series_df['HOUR OF DAY'].unique().tolist()\n",
    "unique_hours.sort()\n",
    "hour_of_day_df['HOUR OF DAY'] = unique_hours\n",
    "\n",
    "# Days in week\n",
    "day_in_week_df = base_data.copy()\n",
    "unique_days = time_series_df['WEEKDAY'].unique().tolist()\n",
    "unique_days.sort()\n",
    "day_in_week_df['WEEKDAY'] = unique_days\n",
    "\n",
    "# Hours in week\n",
    "hour_of_week_df = base_data.copy()\n",
    "unique_hours_week = time_series_df['HOUR OF WEEK'].unique().tolist()\n",
    "unique_hours_week.sort()\n",
    "hour_of_week_df['HOUR OF WEEK'] = unique_hours_week\n",
    "\n",
    "# Month in year\n",
    "month_in_year_df = base_data.copy()\n",
    "unique_months = time_series_df['MONTH'].unique().tolist()\n",
    "unique_months.sort()\n",
    "month_in_year_df['MONTH'] = unique_months\n",
    "\n",
    "# Year (exclude 2012 and 2020 as these are not whole in the data)\n",
    "year_df = base_data.copy()\n",
    "no_interval_df = no_interval_df[no_interval_df['YEAR'] != 2020]\n",
    "no_interval_df = no_interval_df[no_interval_df['YEAR'] != 2012]\n",
    "unique_years = no_interval_df['YEAR'].unique().tolist()\n",
    "unique_years.sort()\n",
    "year_df['YEAR'] = unique_years\n",
    "\n",
    "# Years for dead\n",
    "dead_year_df = year_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function that fills the dataframes used for bokeh\n",
    "def fill_df_for_bokeh(dataframe, out_dataframe, column_string, type_of_time_series, dead=False):\n",
    "    \n",
    "    # Loop through accident types\n",
    "    for accident_type in range(len(accident_types)):\n",
    "        # Store number of accidents for type in dataframe\n",
    "        # and create dataframe to store number of accidents for type and \n",
    "        # which type of time series is currently being used\n",
    "        if dead:\n",
    "            total_num_accidents_for_type = dataframe['NUMBER OF ' + str(accident_types[accident_type]) + ' KILLED'].sum()\n",
    "            temp_df = dataframe[[column_string, 'NUMBER OF ' + str(accident_types[accident_type]) + ' KILLED']].copy()\n",
    "        else:\n",
    "            total_num_accidents_for_type = dataframe[accident_types[accident_type]].sum()\n",
    "            temp_df = dataframe[[column_string, accident_types[accident_type]]].copy()\n",
    "    \n",
    "        # Loop through the time series passed to the function\n",
    "        for indx, i in enumerate(type_of_time_series):\n",
    "            # Create dataframe to store data for current value of time series,\n",
    "            # e.g. current hour in hours\n",
    "            temp_df_time_series_type = temp_df[temp_df[column_string] == i]\n",
    "            # Calculate number of accidents for type and current time series\n",
    "            if dead:\n",
    "                num_accidents_for_time_series_type = temp_df_time_series_type['NUMBER OF ' + str(accident_types[accident_type]) + ' KILLED'].sum()\n",
    "            else:\n",
    "                num_accidents_for_time_series_type = temp_df_time_series_type[accident_types[accident_type]].sum()\n",
    "            # Insert calculated data into dataframes (month and years need different indexing)\n",
    "            if column_string == 'MONTH': \n",
    "                out_dataframe.iloc[i-1,accident_type] = num_accidents_for_time_series_type\n",
    "            elif column_string == 'YEAR':\n",
    "                out_dataframe.iloc[indx,accident_type] = num_accidents_for_time_series_type\n",
    "            else:\n",
    "                out_dataframe.iloc[i,accident_type] = num_accidents_for_time_series_type\n",
    "\n",
    "# Fill dataframes for all types of time_series\n",
    "fill_df_for_bokeh(time_series_df, hour_of_day_df, 'HOUR OF DAY', unique_hours)\n",
    "fill_df_for_bokeh(time_series_df, day_in_week_df, 'WEEKDAY', unique_days)\n",
    "fill_df_for_bokeh(time_series_df, hour_of_week_df, 'HOUR OF WEEK', unique_hours_week)\n",
    "fill_df_for_bokeh(time_series_df, month_in_year_df, 'MONTH', unique_months)\n",
    "fill_df_for_bokeh(no_interval_df, year_df, 'YEAR', unique_years)\n",
    "fill_df_for_bokeh(no_interval_df, dead_year_df, 'YEAR', unique_years, dead=True)\n",
    "\n",
    "# Rename columns for dead year dataframe, since this looks better when plotted\n",
    "dead_year_df.rename(columns={'TOTAL':'NUMBER OF TOTAL KILLED',\n",
    "                             'PEDESTRIANS':'NUMBER OF PEDESTRIANS KILLED',\n",
    "                             'MOTORISTS':'NUMBER OF MOTORISTS KILLED', \n",
    "                             'CYCLISTS':'NUMBER OF CYCLISTS KILLED'},\n",
    "                    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for transforming dataframes to columndatasources\n",
    "def create_columndatasources_from_dataframes(*args):\n",
    "    sources = []\n",
    "    for arg in args:\n",
    "        sources.append(ColumnDataSource(arg))\n",
    "    return sources\n",
    "\n",
    "# Create variables for string values for days and month which will be used for plotting\n",
    "days = ('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday')\n",
    "for i, day in enumerate(day_in_week_df['WEEKDAY']):\n",
    "    day_in_week_df.loc[i,'WEEKDAY'] = days[i]\n",
    "    \n",
    "months = ('January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December')\n",
    "for i, day in enumerate(month_in_year_df['MONTH']):\n",
    "    month_in_year_df.loc[i,'MONTH'] = months[i]\n",
    "    \n",
    "# Crate bokeh ColumnDataSources for all dataframes created before, except dead_year_df, \n",
    "# as it will be altered later\n",
    "sources = create_columndatasources_from_dataframes(hour_of_day_df, \n",
    "                                                   day_in_week_df, \n",
    "                                                   hour_of_week_df, \n",
    "                                                   month_in_year_df, \n",
    "                                                   year_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that creates plot given title, labels, xrange and ticks\n",
    "def create_plot(title, x_axis_label, y_axis_label, x_range=None, ticks=None):\n",
    "    \n",
    "    # Include x_range if specified\n",
    "    if x_range is not None:\n",
    "        p_out = figure(plot_height = 400, plot_width = 850, x_range=x_range,\n",
    "               title = title, \n",
    "               x_axis_label = x_axis_label,\n",
    "               y_axis_label = y_axis_label, toolbar_location=None, tools=\"\")\n",
    "    else:\n",
    "        p_out = figure(plot_height = 400, plot_width = 850, \n",
    "               title = title, \n",
    "               x_axis_label = x_axis_label,\n",
    "               y_axis_label = y_axis_label, toolbar_location=None, tools=\"\")\n",
    "        \n",
    "    # If ticks is passed, use these for the plot\n",
    "    if ticks is not None:\n",
    "        p_out.xaxis.ticker = ticks\n",
    "    \n",
    "    return p_out\n",
    "\n",
    "# Create custom colors as a hex palette\n",
    "custom = ['#FF6666', '#6699FF', '#33CC00', '#FFCC33']\n",
    "palette = sns.color_palette(custom)\n",
    "pal = palette.as_hex()\n",
    "\n",
    "# x_range_hours_in_week is used to improve x-ticks for hours in week plot\n",
    "x_range_hours_in_week = []\n",
    "for i in range(int(hour_of_week_df.shape[0] / 12)+1):\n",
    "    x_range_hours_in_week.append(i*12)\n",
    "\n",
    "# Create ps list to store bokeh plots\n",
    "ps = []\n",
    "\n",
    "# Create plots for all time series\n",
    "# Hour in day\n",
    "ps.append(create_plot('Accidents for every Hour of the Day', 'Hour of the Day', 'Number of Accidents', ticks=list(range(0, 24))))\n",
    "# Days in week\n",
    "ps.append(create_plot('Accidents for every Day in the Week', 'Day in Week', 'Number of Accidents', x_range=FactorRange(*days)))\n",
    "# Hour in week\n",
    "ps.append(create_plot('Accidents for every Hour of the Week', 'Hour of the Week', 'Number of Accidents', ticks=x_range_hours_in_week))\n",
    "# Month in year\n",
    "ps.append(create_plot('Accidents for every Month of the Year', 'Month', 'Number of Accidents', x_range=FactorRange(*months)))\n",
    "# Year\n",
    "ps.append(create_plot('Accidents for every Year', 'Year', 'Number of Accidents', ticks=unique_years))\n",
    "\n",
    "# Create list of x values for bokeh ColumnDataSources\n",
    "xs = ('HOUR OF DAY', 'WEEKDAY', 'HOUR OF WEEK', 'MONTH', 'YEAR')\n",
    "\n",
    "# Create bar plots for all plots in ps\n",
    "for j, p in enumerate(ps):\n",
    "    bar = {}\n",
    "    items = [] \n",
    "\n",
    "    for indx, i in enumerate(accident_types):\n",
    "        if indx == 0: mute_bool = True\n",
    "        else: mute_bool = False\n",
    "        bar[i] = p.vbar(x=xs[j], \n",
    "                        muted_alpha=0.03, \n",
    "                        fill_alpha=0.7,  \n",
    "                        line_color=(0,0,0,0.0), \n",
    "                        muted=mute_bool, \n",
    "                        width=0.6, \n",
    "                        top=i, \n",
    "                        color=pal[indx], \n",
    "                        muted_color=pal[indx], \n",
    "                        source=sources[j])\n",
    "        items.append((i, [bar[i]])) \n",
    "    \n",
    "    # Add legend with click policy mute\n",
    "    legend = Legend(items=items, location=(0,220)) \n",
    "    p.add_layout(legend, 'left')\n",
    "    p.legend.click_policy=\"mute\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new plot for dead per year\n",
    "p_dead_year = create_plot('Deaths per Year', 'Year', 'Count', ticks=unique_years)\n",
    "\n",
    "# To highlight the year, make darker colors for all colors in the\n",
    "# defined pallette\n",
    "darker_custom = ['#CC0000', '#0033FF', '#006600', '#FF6600']\n",
    "darker_pal = sns.color_palette(darker_custom)\n",
    "darker_pal = darker_pal.as_hex()\n",
    "\n",
    "bar = {}\n",
    "items = [] \n",
    "\n",
    "# Include only accident 1 and 3 (pedestrians and cyclists)\n",
    "acc_min = 1\n",
    "acc_max = 3\n",
    "\n",
    "# Create colors in dead_year_df for the plot\n",
    "for i, acc in enumerate(accident_types):\n",
    "    color_list = (pal[i], pal[i], pal[i], pal[i], pal[i], pal[i], darker_pal[i])\n",
    "    dead_year_df['NUMBER OF ' + acc + ' KILLED COLOR'] = color_list\n",
    "\n",
    "# Convert dead_year_df to a bokeh ColumnDataSource\n",
    "dead_df_source =  ColumnDataSource(dead_year_df)\n",
    "\n",
    "# Create bar plots as before\n",
    "for indx, i in enumerate(accident_types[acc_min:acc_max]):\n",
    "    i = 'NUMBER OF ' + i + ' KILLED'\n",
    "    bar[i] = p_dead_year.vbar(x='YEAR', \n",
    "                    muted_alpha=0.03, \n",
    "                    fill_alpha=0.7,  \n",
    "                    line_color=(0,0,0,0.0), \n",
    "                    muted=False, \n",
    "                    width=0.6, \n",
    "                    top=i, \n",
    "                    color = i + ' COLOR',\n",
    "                    muted_color = i + ' COLOR',\n",
    "                    source=dead_df_source)\n",
    "    items.append((i, [bar[i]])) \n",
    "\n",
    "legend = Legend(items=items, location=(0,260)) \n",
    "p_dead_year.add_layout(legend, 'left')\n",
    "p_dead_year.legend.click_policy=\"mute\"\n",
    "\n",
    "show(p_dead_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph, it can be seen that the number of deaths for cyclists in 2019 exceeded the number for all other years, and the number for pedestrians is likewise rising. From this, the results of the program do not seem promising. \n",
    "\n",
    "To understand the causes behind these fatal accidents, the contributing factors were investigated. Driver inattention or distraction, failure to yield, and disregarded traffic signs were the three major contributors responsible for the deaths of pedestrians or cyclists. Additionally, it can be seen that most factors excluding pedestrian or cyclist error are related to motorists. The graph below illustrates all recorded contributing factors for the deaths of pedestrians or cyclists in 2019. To see the numbers behind the plot, simply hover over the area of interest within the pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe with needed attributes (number of killed cyclist/pedestrians and contributions)\n",
    "pie_data = interval_data[['CRASH DATE','NUMBER OF PEDESTRIANS KILLED','NUMBER OF CYCLIST KILLED','CONTRIBUTING FACTOR VEHICLE 1']].copy()\n",
    "\n",
    "# combine number of killed people in one column for both pedestrians and cyclists\n",
    "pie_data['PEDESTRIANS/CYCLIST KILLED'] = pie_data['NUMBER OF PEDESTRIANS KILLED'] + pie_data['NUMBER OF CYCLIST KILLED']\n",
    "\n",
    "# select only needed columns\n",
    "pie_data = pie_data[['PEDESTRIANS/CYCLIST KILLED', 'CONTRIBUTING FACTOR VEHICLE 1']]\n",
    "\n",
    "# removing datapoints where they are all zeros\n",
    "pie_data = pie_data[(pie_data[['PEDESTRIANS/CYCLIST KILLED']] != 0).any(axis=1)]\n",
    "pie_data = pie_data[(pie_data[['CONTRIBUTING FACTOR VEHICLE 1']] != 0).any(axis=1)]\n",
    "# removing dat where the contributing factor is unspecified\n",
    "pie_data = pie_data[(pie_data[['CONTRIBUTING FACTOR VEHICLE 1']] != 'Unspecified').any(axis=1)]\n",
    "\n",
    "# groupby contributing factor and count the number of killed pedestrians/cyclists for each contributing factor for the pie chart\n",
    "x = pie_data.groupby('CONTRIBUTING FACTOR VEHICLE 1').count()\n",
    "\n",
    "# convert it to a distionary\n",
    "x = x.to_dict('dict')\n",
    "\n",
    "# removing outer level of dictionary\n",
    "x = x['PEDESTRIANS/CYCLIST KILLED']\n",
    "\n",
    "# combining dictionary keys where the values are low\n",
    "other = x['Aggressive Driving/Road Rage'] + x['Driver Inexperience'] + x['Driverless/Runaway Vehicle'] + x['Illnes'] + x['Oversized Vehicle'] + x['Pavement Slippery'] + x['Unsafe Lane Changing']\n",
    "\n",
    "#creating dictionary based on key values in dictionary\n",
    "x = {\n",
    "    'Driver Inattention/Distraction': x['Driver Inattention/Distraction'],\n",
    "    'Failure to yield': x['Failure to Yield Right-of-Way'],\n",
    "    'Traffic signs disregarded': x['Traffic Control Disregarded'],\n",
    "    'Pedestrian/cyclist error': x['Pedestrian/Bicyclist/Other Pedestrian Error/Confusion'],\n",
    "    'Unsafe speed': x['Unsafe Speed'],\n",
    "    'Alcohol': x['Alcohol Involvement'],\n",
    "    'Backing unsafely': x['Backing Unsafely'],\n",
    "    'Other': other,\n",
    "}\n",
    "\n",
    "# plotting data using bokeh in a pie chart form\n",
    "data = pd.Series(x).reset_index(name='value').rename(columns={'index':'factors'})\n",
    "data['angle'] = data['value']/data['value'].sum() * 2*pi\n",
    "data['color'] = GnBu[len(x)]\n",
    "\n",
    "p = figure(plot_height=450,plot_width=700, title=\"Contributing factors responsible for the death of pedestrians/cyclists involved in traffic accidents in 2019\", toolbar_location=None,\n",
    "           tools=\"hover\", tooltips=\"@factors: @value\", x_range=(-0.5, 1.0))\n",
    "\n",
    "p.wedge(x=0, y=1, radius=0.4,\n",
    "        start_angle=cumsum('angle', include_zero=True), end_angle=cumsum('angle'),\n",
    "        line_color=\"white\", fill_color='color', legend_field='factors', source=data)\n",
    "\n",
    "data[\"value\"] = data['value'].astype(str)\n",
    "data[\"value\"] = data[\"value\"].str.pad(35, side = \"left\")\n",
    "source = ColumnDataSource(data)\n",
    "\n",
    "p.axis.axis_label=None\n",
    "p.axis.visible=False\n",
    "p.grid.grid_line_color = None\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, this project will explore the trends for traffic related deaths and accidents to investigate their causes to see what actions can be taken to fulfill the visions of Mayor Bill de Blasio. \n",
    "This project will use the NYC Motor Vehicle Collisions - Crashes data (NYC OpenData, 2014), provided by the NYC Police Department and published by NYC OpenData. In the dataset, collision records since July 2012 are noted and are updated daily. Each crash record contains information about date, time, location and injured or killed people, as well as contributing factors and vehicle types involved. Due to the considerable size of this dataset, this project will be using data from the year of 2019 unless stated otherwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start exploring the dataset, and it’s contents, a confusion matrix was created in order to explore the relationship between the variables. Other than the correlation between Latitude and Longitude, little to no relationship was observed amongst the remaining variables. This could indicate that it is unlikely that the crashes are caused by a single factor, and therefore an extensive exploration into the different attributes and components of the dataset will be carried out in the hopes of finding patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to use for bokeh plots, containing number of pedestrians, \n",
    "# cyclists, and motorists injured or killed in different time series\n",
    "time_series_df = interval_data[['CRASH DATE', 'CRASH TIME','LATITUDE',\n",
    "       'LONGITUDE','NUMBER OF PERSONS INJURED',\n",
    "       'NUMBER OF PERSONS KILLED', 'NUMBER OF PEDESTRIANS INJURED',\n",
    "       'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED',\n",
    "       'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED',\n",
    "       'NUMBER OF MOTORIST KILLED']].copy()\n",
    "\n",
    "time_series_df = interval_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column to store hour of day\n",
    "time_series_df['HOUR OF DAY'] = pd.to_datetime(time_series_df['CRASH TIME']).dt.hour.copy()\n",
    "\n",
    "# Create column to store day of the week\n",
    "time_series_df['WEEKDAY'] = pd.to_datetime(time_series_df['CRASH DATE']).dt.dayofweek.copy()\n",
    "\n",
    "\n",
    "# Create column to store hour of the week\n",
    "time_series_df['HOUR OF WEEK'] = time_series_df['WEEKDAY'] * 24 + time_series_df['HOUR OF DAY']\n",
    "\n",
    "# Create column to store month \n",
    "time_series_df['MONTH'] = pd.to_datetime(time_series_df['CRASH DATE']).dt.month.copy()\n",
    "\n",
    "# Create a column to store week\n",
    "time_series_df['WEEK'] = pd.to_datetime(time_series_df['CRASH DATE']).dt.week.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge number of injured and dead for pedestrians, persons, cyclists, and motorists\n",
    "time_series_df['PERSONS'] = time_series_df['NUMBER OF PERSONS INJURED'] + time_series_df['NUMBER OF PERSONS KILLED']\n",
    "time_series_df['PEDESTRIANS'] = time_series_df['NUMBER OF PEDESTRIANS INJURED'] + time_series_df['NUMBER OF PEDESTRIANS KILLED']\n",
    "time_series_df['CYCLISTS'] = time_series_df['NUMBER OF CYCLIST INJURED'] + time_series_df['NUMBER OF CYCLIST KILLED']\n",
    "time_series_df['MOTORISTS'] = time_series_df['NUMBER OF MOTORIST INJURED'] + time_series_df['NUMBER OF MOTORIST KILLED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode contributing factor and vehicle type. Set NAN values to -1.\n",
    "# I cannot get the labelencoder from sklearn to work, so I will just do it manually\n",
    "\n",
    "time_series_df['CONTRIBUTING FACTOR VEHICLE 1'] = pd.Categorical(time_series_df['CONTRIBUTING FACTOR VEHICLE 1'])\n",
    "time_series_df['CONTRIBUTING FACTOR VEHICLE 1'] = time_series_df['CONTRIBUTING FACTOR VEHICLE 1'].cat.codes\n",
    "\n",
    "time_series_df['CONTRIBUTING FACTOR VEHICLE 2'] = pd.Categorical(time_series_df['CONTRIBUTING FACTOR VEHICLE 2'])\n",
    "time_series_df['CONTRIBUTING FACTOR VEHICLE 2'] = time_series_df['CONTRIBUTING FACTOR VEHICLE 2'].cat.codes\n",
    "\n",
    "time_series_df['CONTRIBUTING FACTOR VEHICLE 3'] = pd.Categorical(time_series_df['CONTRIBUTING FACTOR VEHICLE 3'])\n",
    "time_series_df['CONTRIBUTING FACTOR VEHICLE 3'] = time_series_df['CONTRIBUTING FACTOR VEHICLE 3'].cat.codes\n",
    "\n",
    "time_series_df['CONTRIBUTING FACTOR VEHICLE 4'] = pd.Categorical(time_series_df['CONTRIBUTING FACTOR VEHICLE 4'])\n",
    "time_series_df['CONTRIBUTING FACTOR VEHICLE 4'] = time_series_df['CONTRIBUTING FACTOR VEHICLE 4'].cat.codes\n",
    "\n",
    "time_series_df['CONTRIBUTING FACTOR VEHICLE 5'] = pd.Categorical(time_series_df['CONTRIBUTING FACTOR VEHICLE 5'])\n",
    "time_series_df['CONTRIBUTING FACTOR VEHICLE 5'] = time_series_df['CONTRIBUTING FACTOR VEHICLE 5'].cat.codes\n",
    "\n",
    "time_series_df['VEHICLE TYPE CODE 1'] = pd.Categorical(time_series_df['VEHICLE TYPE CODE 1'])\n",
    "time_series_df['VEHICLE TYPE CODE 1'] = time_series_df['VEHICLE TYPE CODE 1'].cat.codes\n",
    "\n",
    "time_series_df['VEHICLE TYPE CODE 2'] = pd.Categorical(time_series_df['VEHICLE TYPE CODE 2'])\n",
    "time_series_df['VEHICLE TYPE CODE 2'] = time_series_df['VEHICLE TYPE CODE 2'].cat.codes\n",
    "\n",
    "time_series_df['VEHICLE TYPE CODE 3'] = pd.Categorical(time_series_df['VEHICLE TYPE CODE 3'])\n",
    "time_series_df['VEHICLE TYPE CODE 3'] = time_series_df['VEHICLE TYPE CODE 3'].cat.codes\n",
    "\n",
    "time_series_df['VEHICLE TYPE CODE 4'] = pd.Categorical(time_series_df['VEHICLE TYPE CODE 4'])\n",
    "time_series_df['VEHICLE TYPE CODE 4'] = time_series_df['VEHICLE TYPE CODE 4'].cat.codes\n",
    "\n",
    "time_series_df['VEHICLE TYPE CODE 5'] = pd.Categorical(time_series_df['VEHICLE TYPE CODE 5'])\n",
    "time_series_df['VEHICLE TYPE CODE 5'] = time_series_df['VEHICLE TYPE CODE 5'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr =time_series_df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9));\n",
    "plt.title('Correlation Matrix', fontsize=20)\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Temporal Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something that could provide useful insight into causes behind the accidents is to look for patterns in temporal data. Therefore, the number of accidents for each victim type, i.e. pedestrians, cyclists, and motorists, and total number of accidents for all victim types are plotted against different types of temporal data in the following graphs. The temporal data used is hour of day, day in week, hour in week, month in year, and year. Except for the latter, these graphs will only include data for 2019. The number of deaths and injuries have been combined. The legend (box to the left) of the graphs can be clicked to select and deselect the type of persons involved to better explore the trends between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(ps[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above, for all the types of people, it can be seen that crashes are most likely to occur during daytime, around 8 am and from around 2 pm till 6 pm, than during nighttime, however a spike can be seen around midnight. The accidents during the aforementioned daytime hours could be due to rush hours where people are going to and from their job, school or the like. The spike at 12 pm could be related to driving under the influence or simply driver exhaustion leading to inattentive driving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(ps[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at accidents across the days in the week, it can be seen that most accidents occur during weekdays, Friday generally having the highest number of accidents. This could support the interpretation for the previous graph regarding higher accident rates due to rush hours. Friday being the worst day could be related to the fact that it’s the day people can begin their weekend and therefore might be more likely to have plans after work that differ from plans during the other weekdays.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(ps[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph for accidents for every hour in the week shows similar patterns as were observed in the two previous graphs. Again, generally there are less accidents during the weekend, which is from hour 120 of the week till hour 168, however, the accident rate is higher during nighttime in the weekend than during the weekdays. This is likely caused by the fact that people are off work and are staying out till a later hour than during the weekdays, and could perhaps be linked to a higher alcohol intake for the same reasons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(ps[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the months, looking at all types of people combined, there are more accidents from around May till October, and fewer for January and February, however an increase can be observed for December. An interesting observation can be made looking at the accidents for pedestrians and cyclists. The accident rate for pedestrians is more or less steady throughout the year, where the accident rate for cyclists is highest from Spring till Fall. A reason could be that people are more likely to use their bike when the weather is good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(ps[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final temporal pattern plot, the accident rates are seen for all years in the dataset, excluding 2012 and 2020, as data was not recorded for the entirety of these years. It can be seen that the accident rate for motorists is rising from 2014-2019, while remaining steady for pedestrians and cyclists. However, as was seen earlier, the death rate for these has been rising during the later years. Regardless, the overall accident rate and death rate has not been declining since 2014, and it can again be concluded that the results of the implementation of Vision Zero cannot yet be seen.\n",
    "\n",
    "The temporal patterns explored in this section indicated that the accident rate is higher during weekdays, especially Friday, and in rush hours where people are going to and from work or school. Accidents during the nighttime in the weekend were higher than during nighttime in the week, and could be related to alcohol or simply the fact that people stay out later during the weekend than weekdays. Furthermore, accidents seem more likely to occur from spring till late fall, however with an increase for December. Less accidents are seen in January and February, the reason being unknown. It could be related to improved individual behavior and mentality at the start of a new year, but this is simply speculation. Another reason could be that the temperatures for these two months are the lowest for all months in the year (Current Results (n.d.)), however that could also result in more people choosing the car than walking, which looking at the contributing factors to accidents should in principle cause more accidents. Looking at the months of the year, it could be suggested that since the accident rate for bicyclists is higher from Spring till Fall, weather could have an influence in the number of accidents, since people are more unlikely to use their bicycle in the case of bad weather.  Further investigations would have to be made to draw final conclusions, but the temporal patterns do provide an insight into the accident rates and its causes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Exploring Geographical Patterns \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the geographical trends in the data is an important next step in order to find trends in accidents related to specific areas of the city, or streets. The data for the number of injured or killed was combined for each of the types of victims, namely, pedestrians, cyclists, and motorists. \n",
    "\n",
    "In the map below, the geographical data for accidents where pedestrians were injured or killed in 2019 is plotted. It can be noticed that there is a concentration of accidents where pedestrians are involved in the Manhattan region, excluding the Central Park area which is seen as the area of no accidents in Manhattan. The Manhattan region of the city is the most densely populated region in New York City, and it doesn’t fall short of streets full with traffic and pedestrians (World Population Review, 2020). Moving away from Manhattan, Queens, Bronx and Staten Island have less density of accidents. However, they do have regions of more accidents. This could be due to the fact that they are less densely packed, furthermore, since Manhattan has a larger amount of points of interest such as Times Square and Central Park, and the borough is quite significantly smaller in land area, it is natural to see these trends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop nan location values because we want to plot them\n",
    "df_heat = df.copy()\n",
    "df_heat = df_heat.dropna(subset=['LATITUDE', 'LONGITUDE']).copy()\n",
    "\n",
    "# create list of strings for each class to be used in loop in order to easily iterate through the classes and sample the data\n",
    "classes = ['PEDESTRIANS', 'MOTORIST','CYCLIST']\n",
    "# year of interest\n",
    "year = '2019'\n",
    "maps = []\n",
    "# html code to include a title in the maps\n",
    "titles = ['''<h3 align=\"center\" style=\"font-size:20px\"><b>Pedestrians Injured or Killed in NYC</b></h3>''',\n",
    "          '''<h3 align=\"center\" style=\"font-size:20px\"><b>Motorists Injured or Killed in NYC</b></h3>''',\n",
    "          '''<h3 align=\"center\" style=\"font-size:20px\"><b>Cyclists Injured or Killed in NYC</b></h3>''']\n",
    "\n",
    "# loops through each of the classes in order to create a seperate map with different data\n",
    "for i, victim in enumerate(classes):\n",
    "    \n",
    "    # necessary strings to identify columns in the dataset using specific class\n",
    "    killed_text = 'NUMBER OF ' + victim + ' KILLED'\n",
    "    injured_text = 'NUMBER OF ' + victim + ' INJURED'\n",
    "    new_col_text = victim + ' INJURED/KILLED'\n",
    "    \n",
    "    # selecting desired data from df\n",
    "    heat_df = df_heat[['CRASH DATE', 'LATITUDE','LONGITUDE', killed_text, injured_text]]\n",
    "    # creating a new column including the combination of injured and killed victims\n",
    "    heat_df[new_col_text] = heat_df[killed_text] + heat_df[injured_text]\n",
    "    \n",
    "    # replace missing values in new columns with nan to easily remove these datapoints\n",
    "    heat_df[new_col_text] = heat_df[new_col_text].replace(0, np.nan)\n",
    "    heat_df = heat_df.dropna(subset=[new_col_text])\n",
    "    \n",
    "    # selecting desired data from heat_df\n",
    "    heat_df = heat_df[['CRASH DATE', 'LATITUDE','LONGITUDE',new_col_text]]\n",
    "    \n",
    "    # converting date column to datetime\n",
    "    heat_df['CRASH DATE'] = pd.to_datetime(heat_df['CRASH DATE'])\n",
    "    \n",
    "    # cutting down data by selecting year of interest\n",
    "    heat_df['YEAR'] = heat_df['CRASH DATE'].dt.year\n",
    "    heat_df['YEAR'] = heat_df['YEAR'].astype(str)\n",
    "    heat_df = heat_df[heat_df['YEAR']==year]\n",
    "    \n",
    "    # converting lat/long to float\n",
    "    heat_df['LATITUDE'] = heat_df['LATITUDE'].astype(float)\n",
    "    heat_df['LONGITUDE'] = heat_df['LONGITUDE'].astype(float)\n",
    "    \n",
    "    # we only want to plot lat/long\n",
    "    heat_df = heat_df[['LATITUDE', 'LONGITUDE']]\n",
    "    heat_df = [[row['LATITUDE'],row['LONGITUDE']] for index, row in heat_df.iterrows()]\n",
    "    \n",
    "    # Create heatmap\n",
    "    Heat_map = folium.Map(location=[40.730610, -73.935242], zoom_start = 12) \n",
    "    \n",
    "    HeatMap(heat_df, radius=10, max_zoom=10).add_to(Heat_map)\n",
    "\n",
    "    title_html = titles[i]\n",
    "    Heat_map.get_root().html.add_child(folium.Element(title_html))\n",
    "    \n",
    "    # append heatmap to list in order to plot it later\n",
    "    maps.append(Heat_map)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pedestrians Injured or Killed\n",
    "maps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the pedestrian map, it was thought that it would be interesting to investigate areas that have a large concentration of casualties. After investigating several areas using Google Maps StreetView, it was noticed that these areas are busy pedestrian streets. Furthermore, it was noticed that intersections were a common place where accidents occurred all around the city. An example of an intersection was selected that lies on the 7th Avenue (shown below). It is noticed that this is a shopping street where there are many restaurants and stores crammed with people. The fact that there is a concentrated area of pedestrian related casualties is evident due to the large concentration of pedestrians and cars travelling in this street. But this trend is not limited to this crossroad, along 7th avenue there are many casualties. This could be due to this being a busy street with many pedestrians and motorists travelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=188K2_nR7CyJ_SpRq1IF6c9BHozgH5RpW\" alt=\"Image\" height=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot less cyclist related accidents recorded compared to pedestrians and motorists, but similar trends can be noticed compared to the previous. Manhattan is once again seen as an area where more casualties occur where cyclists get injured or killed, once again this could be due to this being the center of the city and a densely packed area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclists Injured or Killed\n",
    "maps[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps by once again looking at some areas where there is a large concentration of cyclist related accidents, it will be possible to bring up some possible reasons for the cause of these accidents. An intersection was chosen from 5th Avenue as an example (shown below). Google Maps Street View was once again used for the above photo of this intersection. This looks to be a busy street with both pedestrians and cars. Additionally, some cyclists are seen in this intersection where there are no bike lanes. If it is a common trend that there aren’t many bike lanes across the city, it could indicate that there is a danger to being a biker in NYC and this puts cyclists in this city in a vulnerable position. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1WhpgrNfeMB3TDc1AWS8stm_yfIVuMYpl\" alt=\"Image\" height=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a disproportionate amount of more data points related to injured or killed motorists in accidents. This is evident since this dataset relates to motor vehicle crashes. In the heatmap below, all motoirst related casualties in 2019 are plotted in order to see whether there are patterns in the distribution of accidents. Due to the larger amount of data points for this victim type, it is hard to see from this distance in the map what are the trends. However, by zooming in to Manhattan, and other areas of the city it was noticed that accidents are often occuring in intersections. When looking at a larger street such as 7th Avenue, this pattern is clearly seen for every intersection. Intersections are an occasion where it highly relies on attention, ability to yield, and regard to traffic lights in order to avoid colliding with cars coming from other directions. Relating back to the pie chart illustrating the contributing factors in pedestrian and cyclist casualties, it was seen that a large proportion was related to driver inattention or distraction, failure to yield, and disregard to traffic signs, this could have a connection to the amount of accidents that occur in intersections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the geographical data and the temporal data in conjunction could provide a new perspective of the data than what the two can provide on their own. In the following time-lapse, the temporal trends previously described can be seen for the different hours of the day. Comparing the number of accidents at 5 pm to those at 1 am, it is clear that the concentration of accidents differ greatly since 5 pm lies in rush hour. Furthermore, it can be noticed that there are some areas in Manhattan and Brooklyn that are consistently showing large numbers of accidents throughout most hours of the day.\n",
    "\n",
    "Note: to play the time lapse, use the vertical boxes to the left in the plot. Their functions can be seen when hovering over them, but going from the box in the top to the buttom, their functions are: _Backward_, _Play Reverse_, _Play_, _Forward_, and _Loop_. The number displayed in the buttom shows the hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to use for bokeh plots, containing number of pedestrians, \n",
    "# cyclists, and motorists injured or killed in different time series\n",
    "time_series_df = interval_data[['CRASH DATE', 'CRASH TIME','LATITUDE',\n",
    "       'LONGITUDE','NUMBER OF PERSONS INJURED',\n",
    "       'NUMBER OF PERSONS KILLED', 'NUMBER OF PEDESTRIANS INJURED',\n",
    "       'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED',\n",
    "       'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED',\n",
    "       'NUMBER OF MOTORIST KILLED']].copy()\n",
    "\n",
    "# Create column to store hour of day\n",
    "time_series_df['HOUR OF DAY'] = pd.to_datetime(time_series_df['CRASH TIME']).dt.hour.copy()\n",
    "\n",
    "# Create column to store day of the week\n",
    "time_series_df['WEEKDAY'] = pd.to_datetime(time_series_df['CRASH DATE']).dt.dayofweek.copy()\n",
    "\n",
    "# Create column to store hour of the week\n",
    "time_series_df['HOUR OF WEEK'] = time_series_df['WEEKDAY'] * 24 + time_series_df['HOUR OF DAY']\n",
    "\n",
    "# Create column to store month \n",
    "time_series_df['MONTH'] = pd.to_datetime(time_series_df['CRASH DATE']).dt.month.copy()\n",
    "\n",
    "#Create a column to store week\n",
    "time_series_df['WEEK'] = pd.to_datetime(time_series_df['CRASH DATE']).dt.week.copy()\n",
    "\n",
    "# Merge number of injured and dead for pedestrians, persons, cyclists, and motorists\n",
    "time_series_df['PERSONS'] = time_series_df['NUMBER OF PERSONS INJURED'] + time_series_df['NUMBER OF PERSONS KILLED']\n",
    "time_series_df['PEDESTRIANS'] = time_series_df['NUMBER OF PEDESTRIANS INJURED'] + time_series_df['NUMBER OF PEDESTRIANS KILLED']\n",
    "time_series_df['CYCLISTS'] = time_series_df['NUMBER OF CYCLIST INJURED'] + time_series_df['NUMBER OF CYCLIST KILLED']\n",
    "time_series_df['MOTORISTS'] = time_series_df['NUMBER OF MOTORIST INJURED'] + time_series_df['NUMBER OF MOTORIST KILLED']\n",
    "\n",
    "# Drop not needed columns\n",
    "time_series_df = time_series_df.drop(['NUMBER OF PERSONS INJURED',\n",
    "       'NUMBER OF PERSONS KILLED', 'NUMBER OF PEDESTRIANS INJURED',\n",
    "       'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED',\n",
    "       'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED',\n",
    "       'NUMBER OF MOTORIST KILLED'], axis=1)\n",
    "\n",
    "# Reset indices after drop\n",
    "time_series_df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "# The PERSON column is of type float, change to integer\n",
    "time_series_df['PERSONS'] = time_series_df['PERSONS'].astype(int)\n",
    "\n",
    "# Only keep the rows where Latitude and Longitude values are present\n",
    "time_series_df = time_series_df.dropna(subset=['LATITUDE'])\n",
    "time_series_df = time_series_df.dropna(subset=['LONGITUDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBaseMap(default_location=[40.730610, -73.935242], default_zoom_start=12):\n",
    "    base_map = folium.Map(location=default_location, control_scale=True, zoom_start=default_zoom_start)\n",
    "    return base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate time lapse for pedestrians injured/killed everty month\n",
    "month_pedestrian_map = generateBaseMap()\n",
    "title = '''<h3 align=\"center\" style=\"font-size:20px\"><b>Persons Injured or Killed in NYC every Hour of the Day in 2019</b></h3>'''\n",
    "\n",
    "time_lapse_df = time_series_df[time_series_df.PERSONS > 0].copy()\n",
    "time_lapse_df['Weight'] = time_lapse_df['HOUR OF DAY'].copy()\n",
    "time_lapse_df['Weight'] = time_lapse_df['Weight'].astype(float)\n",
    "\n",
    "# List comprehension to make out list of lists\n",
    "time_lapse_df = [[[row['LATITUDE'],row['LONGITUDE']] for index, row in time_lapse_df[time_lapse_df['Weight']==i].iterrows()] for i in range(1,24)]\n",
    "\n",
    "hm = plugins.HeatMapWithTime(time_lapse_df, auto_play=True, max_opacity=0.8)\n",
    "hm.add_to(month_pedestrian_map)\n",
    "\n",
    "month_pedestrian_map.get_root().html.add_child(folium.Element(title))\n",
    "month_pedestrian_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This further supports the observations made that the number of accidents relate to hour of the day and areas of the city. The observations made during this section will be the foundation for the following section, in which explanations for the observed patterns will be investigated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 POV from a Biker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biker in New York City filmed their trip down Broome Street on a Friday in 2018 during a traffic jam (ActionKid, 2018). This 14 minutes long shot gives an impression of what it is like to be a bicyclist in the streets of New York. The video below shows a small part of the full video, but even from this small clip, several concerning factors can be observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video controls src=\"https://drive.google.com/uc?id=1zYoNX-kcf7xWIMJ47kzH7cZ-XDzn505x\" alt=\"Video\" height=\"500\" width=\"700\" style=\"display:block; margin: 0 auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the things that are immediately noticeable are the lack of bicycle lanes and high number of cars. The biker has to bike in and out between the cars, which can easily result in very dangerous situations. Below, another part of the video is shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video controls src=\"https://drive.google.com/uc?id=1uyXITpGXLxx1nrhtM8izgUy5RNqYcJO1\" alt=\"Video\" height=\"500\" width=\"700\" style=\"display:block; margin: 0 auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that in intersections, the drivers have not been following the traffic rules and have therefore ended up stuck in the middle of the intersection and on top of the pedestrian cross roads when the traffic light turns red for their direction. This results in dangerous situations as pedestrians start crossing the streets having to navigate in and out between cars. Overall, these clips show that pedestrians, cyclists, and motorists are likely to end up having to share the same space at the same time, which can result in dangerous situations. These observations support the observations made previously, where it was seen that accidents frequently occur in intersections.\n",
    "\n",
    "Looking at the videos, traffic flow could be a determining factor for the number of accidents and casualties in the traffic. The following section will investigate the relationship between the traffic flow and traffic related accidents in NYC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Traffic flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traffic Volume Count dataset provided by the NYC Department of Transportation and published by NYC OpenData (NYC OpenData, 2018) was used in order to investigate the traffic flow in relation to the number of accidents that occur. This dataset contains information about traffic volume count for specific dates, streets, and directions in NYC for years 2012 to the current date.\n",
    "To compare the data from the two datasets, the data was grouped by hour. Below, the data for traffic flow and number of accidents per hour has been normalized to allow for comparison between the two types of data, as they are on a distinctively different scale. As can be seen, the two distributions looks strikingly similar. Again, the legend in the plot can be clicked to select and deselect the distributions of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group accident_data by day and hour of day\n",
    "times = pd.to_datetime(df['CRASH TIME'])\n",
    "dates = pd.to_datetime(df['CRASH DATE'])\n",
    "accident_group = df.groupby([dates,times.dt.hour]).size().copy()\n",
    "accident_group = accident_group.to_frame('Accidents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve \"NY traffic volumn\" data\n",
    "url = 'https://data.cityofnewyork.us/api/views/ertz-hr4r/rows.csv?accessType=DOWNLOAD'\n",
    "df_2 = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date column to datetime\n",
    "df_2['Date'] = pd.to_datetime(df_2['Date'])\n",
    "df_2 = df_2.drop(['ID', 'Segment ID', 'Roadway Name', 'From', 'To', 'Direction'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns so that they match the ones in the Motor vehicle crash dataset\n",
    "flow_group = df_2.copy()\n",
    "flow_group = flow_group.rename(columns={'12:00-1:00 AM':0,'1:00-2:00AM':1,'2:00-3:00AM':2,'3:00-4:00AM':3,'4:00-5:00AM':4,'5:00-6:00AM':5,'6:00-7:00AM':6,'7:00-8:00AM':7,'8:00-9:00AM':8,'9:00-10:00AM':9,'10:00-11:00AM':10,'11:00-12:00PM':11})\n",
    "flow_group = flow_group.rename(columns={'12:00-1:00PM':12,'1:00-2:00PM':13,'2:00-3:00PM':14,'3:00-4:00PM':15,'4:00-5:00PM':16,'5:00-6:00PM':17,'6:00-7:00PM':18,'7:00-8:00PM':19,'8:00-9:00PM':20,'9:00-10:00PM':21,'10:00-11:00PM':22,'11:00-12:00AM':23})\n",
    "\n",
    "# Group flow_data by date and hour of day\n",
    "flow_group = flow_group.groupby(flow_group['Date'].dt.date).sum().stack()\n",
    "flow_group = flow_group.to_frame('Traffic_flow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the two series into a dataframe and drop NAN values\n",
    "data_merge = pd.concat([flow_group, accident_group], axis=1).reset_index().rename_axis(None, axis=1)\n",
    "data_merge = data_merge.dropna()\n",
    "data_merge = data_merge.rename(columns={'level_0':'Date','level_1':'Hour'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group data by hour\n",
    "data_plot = data_merge.groupby(data_merge['Hour']).sum()\n",
    "data_plot['HOUR'] = data_plot.index\n",
    "data_plot.rename(columns={'Traffic_flow':'Traffic Flow'}, inplace=True)\n",
    "\n",
    "# Normalize traffic flow and accidents\n",
    "data_plot['Traffic Flow'] = data_plot['Traffic Flow'] / np.max(data_plot['Traffic Flow'])\n",
    "data_plot['Accidents'] = data_plot['Accidents'] / np.max(data_plot['Accidents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot for traffic flow and accidents\n",
    "p_tf_acc = create_plot('Traffic Flow and Number of Accidents per Hour', 'Hour', 'Normalized Count', ticks=list(range(0, 24)))\n",
    "\n",
    "# Create custom color palette\n",
    "tf_acc_custom = ['#515A5A', custom[0]]\n",
    "tf_acc_custom_pal = sns.color_palette(tf_acc_custom)\n",
    "tf_acc_custom_pal = tf_acc_custom_pal.as_hex()\n",
    "\n",
    "# Convert data to bokeh ColumnDataSource\n",
    "tf_acc_source = ColumnDataSource(data_plot)\n",
    "\n",
    "# Types is used to loop through the source for the plots\n",
    "types = ['Traffic Flow', 'Accidents']\n",
    "bar = {}\n",
    "items = [] \n",
    "\n",
    "# Create bar plots like before\n",
    "for indx, i in enumerate(types):\n",
    "    bar[i] = p_tf_acc.vbar(x='HOUR', \n",
    "                    muted_alpha=0.03, \n",
    "                    fill_alpha=0.7,  \n",
    "                    line_color=(0,0,0,0.0), \n",
    "                    muted=False, \n",
    "                    width=0.6, \n",
    "                    top=i, \n",
    "                    color = tf_acc_custom_pal[indx],\n",
    "                    muted_color = tf_acc_custom_pal[indx],\n",
    "                    source=tf_acc_source)\n",
    "    items.append((i, [bar[i]])) \n",
    "\n",
    "legend = Legend(items=items, location=(0,260)) \n",
    "p_tf_acc.add_layout(legend, 'left')\n",
    "p_tf_acc.legend.click_policy=\"mute\"\n",
    "show(p_tf_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This supports the observation made earlier regarding accidents being related to rush hours.\n",
    "The plot above indicates that linear regression could be used to predict the number of traffic accidents based on traffic flow. Below, traffic volume count is plotted against the number of accidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = data_merge['Traffic_flow'].values.reshape(-1, 1)\n",
    "y = data_merge['Accidents'].values\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 1/4, random_state = 0)\n",
    "linearRegressor = LinearRegression()\n",
    "\n",
    "linearRegressor.fit(xTrain, yTrain)\n",
    "yPrediction = linearRegressor.predict(xTest)\n",
    "\n",
    "# print(\"The score of the linear regression model is: {}\".format(linearRegressor.score(xTest, yTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group data by hour\n",
    "data_plot = data_merge.groupby(data_merge['Hour']).sum()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = data_plot['Traffic_flow'].values.reshape(-1, 1)\n",
    "y = data_plot['Accidents'].values\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 1/4, random_state = 0)\n",
    "linearRegressor = LinearRegression()\n",
    "\n",
    "linearRegressor.fit(xTrain, yTrain)\n",
    "yPrediction = linearRegressor.predict(xTest)\n",
    "\n",
    "#print(\"The score of the linear regression model is: {}\".format(linearRegressor.score(xTest, yTest))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group data by hour\n",
    "data_plot = data_merge.groupby(data_merge['Hour']).sum()\n",
    "data_plot['HOUR'] = data_plot.index\n",
    "data_plot.rename(columns={'Traffic_flow':'Traffic Flow'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-aggreated data. It does not look like that there is a linear trend\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "plt.scatter(data_merge['Traffic_flow'], data_merge['Accidents'],c='lightblue',edgecolor='blue',alpha=0.8)\n",
    "plt.title('Traffic Volume Count against Traffic Accident Count', fontsize=15)\n",
    "plt.xlabel('Traffic Volume Count')\n",
    "plt.ylabel('Traffic Accident Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just looking at this plot, a relationship between traffic volume count and accident counts is not apparent. However, if the data is aggregated per hour, meaning that all data from e.g. 1-2 am is summed up across all days in the dataset,  the results indicate a positive correlation between the two. This can be seen in the plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the linear trend in the aggreated data\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "plt.scatter(data_plot['Traffic Flow'], data_plot['Accidents'],c='lightblue',edgecolor='blue',alpha=0.8)\n",
    "plt.title('Aggregated Traffic Volume Count against Traffic Accident Count per Hour of the Day', fontsize=15)\n",
    "plt.xlabel('Traffic Volume Count')\n",
    "plt.ylabel('Traffic Accidents Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data behind both of these graphs, a linear regression model was used to predict the number of accidents based on traffic flow. The model built for the data without aggregating by hour got a $R^{2}$ score of 0.08. When aggregating the data by hour, a $R^{2}$ score of 0.95 was reached. This means that in the latter, the model accounts for a large percentage of the variance and the points fall close to the regression line which is the desired outcome when carrying out linear regression.\n",
    "\n",
    "These results show that there is a positive correlation between traffic flow and number of accidents. Predicting the number of accidents based on traffic flow could provide an indication of how many accidents could be expected on a given day or time based on traffic flow data, and thus, necessary allocation of resources can be taken into consideration in order to help prevent as many accidents as possible. This furthermore indicates that a high traffic flow, e.g. during rush hour, is indeed one of the causes for the accidents, as was speculated when watching the video for the POV of a NYC biker. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Predicting victim type \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning could be used to provide intuition on accidents that are yet to happen, and the areas where certain victims are more vulnerable than others. It could also offer the possibility of foreseeing whether certain areas are becoming more or less dangerous in relation to a specific victim type. Perhaps, a valuable tool to aid in the Vision Zero program of eliminating all traffic related deaths in NYC by 2024. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Machine Learning\n",
    "\n",
    "A K-nearest neighbour (KNN) classifier was created for the purpose of predicting, given the location of a victim, whether the victim was a pedestrian, a cyclist, or a motorist. Other machine learning models were also experimented with, such as Logistic Regression, Support Vector Machine, and Neural Networks. However, none of these models produced results that outperformed the KNN model significantly. It was thought that a KNN would be the ideal model for this case since it classifies data points based on feature similarity. An often recommended value of K=3 was used for this model. For this purpose, the accidents where there are multiple types of victims were excluded, thus simplifying the problem and the size of the dataset. The accuracy of the model (60.12%) was arguably low when predicting the victim type for the latitude and longitude coordinates of a part of the dataset never before seen by the model. However, it is likely due to classifying such a precise location is likely to be very hard when there are this many data points that often use the same or similar coordinates. Perhaps by plotting the test data used and the predictions will provide a better insight onto the performance of the model and whether the model was in fact able to capture some of the trends. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to be used for machine learning\n",
    "def replace(val):\n",
    "    return 1 if val > 0 else 0\n",
    "\n",
    "def multiple(row):\n",
    "    return 1 if sum(row) > 1 else 0\n",
    "\n",
    "def mu(row):\n",
    "    if row['MULTIPLE'] == 1:\n",
    "        row['PEDESTRIANS'] = 0\n",
    "        row['CYCLISTS'] = 0\n",
    "        row['MOTORISTS'] = 0\n",
    "    return row\n",
    "\n",
    "# Create functions for classification\n",
    "def encodeOutput(y, hot_encode):\n",
    "    # 0=PEDESTRIANS, 1='CYCLISTS', 2='MOTORISTS', 3='MULTIPLE'\n",
    "\n",
    "    if hot_encode:\n",
    "        # encode class values as integers\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(y)\n",
    "        encoded_y = encoder.transform(y)\n",
    "        # convert integers to dummy variables (i.e. one hot encoded)\n",
    "        return np_utils.to_categorical(encoded_y)\n",
    "    else:\n",
    "        for i, col in enumerate(y.columns.tolist(), 0):\n",
    "            y.loc[:, col] *= i\n",
    "        return y.sum(axis=1)\n",
    "    \n",
    "def logistic(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = LogisticRegression(C=1e5)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred_prob = clf.predict_proba(X_test)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    accuracy_percentage = 100 * accuracy\n",
    "\n",
    "    return y_pred, y_pred_prob, accuracy_percentage\n",
    "\n",
    "def knn(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors=3)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred_prob = clf.predict_proba(X_test)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    accuracy_percentage = 100 * accuracy\n",
    "    \n",
    "    return y_pred, y_pred_prob, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe for machine learning\n",
    "ml_data = df.copy()\n",
    "\n",
    "ml_data = ml_data[['CRASH DATE', 'CRASH TIME', 'LATITUDE', 'LONGITUDE',\n",
    "             'NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED', \n",
    "             'NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF PEDESTRIANS KILLED', \n",
    "             'NUMBER OF CYCLIST INJURED', 'NUMBER OF CYCLIST KILLED', \n",
    "             'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED']]\n",
    "year = 2019\n",
    "ml_data = ml_data[ml_data['CRASH DATE'].dt.year == year]\n",
    "\n",
    "ml_data = ml_data.rename(columns={'CRASH DATE':'DATE'})\n",
    "#df_weather = df_weather.rename(columns={'date':'DATE'})\n",
    "\n",
    "#df_weather = pd.merge(data, df_weather, how='inner')\n",
    "\n",
    "# Create column to store hour of day\n",
    "ml_data['HOUR OF DAY'] = pd.to_datetime(ml_data['CRASH TIME']).dt.hour.copy()\n",
    "# Create column to store day of the week\n",
    "ml_data['WEEKDAY'] = pd.to_datetime(ml_data['DATE']).dt.dayofweek.copy()\n",
    "# Create column to store hour of the week\n",
    "ml_data['HOUR OF WEEK'] = ml_data['WEEKDAY'] * 24 + ml_data['HOUR OF DAY']\n",
    "# Create column to store month \n",
    "ml_data['MONTH'] = pd.to_datetime(ml_data['DATE']).dt.month.copy()\n",
    "\n",
    "ml_data['PEDESTRIANS'] = ml_data['NUMBER OF PEDESTRIANS INJURED'] + ml_data['NUMBER OF PEDESTRIANS KILLED']\n",
    "ml_data['CYCLISTS'] = ml_data['NUMBER OF CYCLIST INJURED'] + ml_data['NUMBER OF CYCLIST KILLED']\n",
    "ml_data['MOTORISTS'] = ml_data['NUMBER OF MOTORIST INJURED'] + ml_data['NUMBER OF MOTORIST KILLED']\n",
    "ml_data['TOTAL'] = ml_data['NUMBER OF PERSONS INJURED'] + ml_data['NUMBER OF PERSONS KILLED']\n",
    "\n",
    "ml_data = ml_data[['LATITUDE', 'LONGITUDE', 'HOUR OF DAY', 'WEEKDAY', 'HOUR OF WEEK', 'MONTH', 'PEDESTRIANS', 'CYCLISTS', 'MOTORISTS']]\n",
    "\n",
    "ml_data = ml_data.dropna()\n",
    "        \n",
    "ml_data['PEDESTRIANS'] = ml_data['PEDESTRIANS'].apply(replace)\n",
    "ml_data['CYCLISTS'] = ml_data['CYCLISTS'].apply(replace)\n",
    "ml_data['MOTORISTS'] = ml_data['MOTORISTS'].apply(replace)\n",
    "\n",
    "ml_data_2 = ml_data[['PEDESTRIANS','CYCLISTS','MOTORISTS']].copy()\n",
    "\n",
    "ml_data_2['MULTIPLE'] = ml_data_2.apply(multiple, axis=1)\n",
    "\n",
    "ml_data_2 = ml_data_2.apply(mu, axis=1)\n",
    "\n",
    "ml_data['PEDESTRIANS'] = ml_data_2['PEDESTRIANS']\n",
    "ml_data['CYCLISTS'] = ml_data_2['CYCLISTS']\n",
    "ml_data['MOTORISTS'] = ml_data_2['MOTORISTS']\n",
    "ml_data['MULTIPLE'] = ml_data_2['MULTIPLE']\n",
    "\n",
    "# removing values where they are all zeros\n",
    "ml_data = ml_data[(ml_data[['PEDESTRIANS','CYCLISTS', 'MOTORISTS', 'MULTIPLE']] != 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ped = ml_data[(ml_data[['PEDESTRIANS']] != 0).any(axis=1)].sample(n=4213,random_state=42)\n",
    "cyc = ml_data[(ml_data[['CYCLISTS']] != 0).any(axis=1)].sample(n=4213,random_state=42)\n",
    "mot = ml_data[(ml_data[['MOTORISTS']] != 0).any(axis=1)].sample(n=4213,random_state=42)\n",
    "\n",
    "balanced = pd.concat([ped, cyc, mot])\n",
    "\n",
    "balanced = balanced.sample(frac=1,random_state=4)\n",
    "\n",
    "X = ml_data[['LATITUDE', 'LONGITUDE']].copy() #, 'HOUR OF WEEK', 'MONTH']].copy()\n",
    "# X = ml_data[['LATITUDE', 'LONGITUDE', 'HOUR OF WEEK', 'MONTH']].copy()\n",
    "y = ml_data[['PEDESTRIANS', 'CYCLISTS', 'MOTORISTS']].copy()\n",
    "\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "y = encodeOutput(y, hot_encode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "classifier = 'KNN'\n",
    "\n",
    "if classifier == 'KNN':\n",
    "    preds, pred_prob, accuracy_percentage = knn(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "elif classifier == 'LOGISTIC':\n",
    "    preds, pred_prob, accuracy_percentage = logistic(X_train, X_test, y_train, y_test)\n",
    "\n",
    "#print(\"Accuracy for \" + classifier + \": \" + str(np.round(accuracy_percentage*100,2)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Plotting Predictions for Machine Learning\n",
    "\n",
    "The accidents for the three victim types motorists, cyclists, and pedestrians can be seen plotted on a map of NYC. Each dot represents an accident that occured in 2019 and in a color representing the different victim types (motorists: yellow, cyclists: green, and pedestrians: blue), which can be seen by clicking on a dot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set NY coordinates\n",
    "NY_coor = [40.730610, -73.935242]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['''<h3 align=\"center\" style=\"font-size:20px\"><b>Accidents in NYC For all Victim Types</b></h3>''',\n",
    "          '''<h3 align=\"center\" style=\"font-size:20px\"><b>Predicted Accidents in NYC For all Victim Types</b></h3>''']\n",
    "\n",
    "# Create Folium map using NY coordinates\n",
    "true_map = folium.Map(location=NY_coor, zoom_start = 10)\n",
    "\n",
    "# Create pop ups for types in map\n",
    "pop_ups = ['Pedestrian', 'Cyclist', 'Motorist']\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    # Set location for map as longitude and latitud in X test\n",
    "    loc_X = X_test.loc[i,'LONGITUDE']\n",
    "    loc_Y = X_test.loc[i,'LATITUDE']\n",
    "    \n",
    "    # Use y_test value to color circle marker\n",
    "    col = pal[1+y_test[i]],\n",
    "    \n",
    "    # Create marker as lat lon with color for X_test\n",
    "    folium.Circle(location=[loc_Y, loc_X],\n",
    "      popup=(pop_ups[preds[i]]),\n",
    "      radius = 100,\n",
    "      fill=True,\n",
    "      fill_color=col,         \n",
    "      color = col,\n",
    "      opacity = 0.8, fill_opacity=0.8).add_to(true_map) \n",
    "\n",
    "# Add title\n",
    "title_html = titles[0]\n",
    "true_map.get_root().html.add_child(folium.Element(title_html))\n",
    "    \n",
    "# Show maps for y_test\n",
    "true_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the map, it can be seen that around the center of Manhattan, cyclists are more likely to be the victims of an accident, as many green dots are concentrated in this area. In Queens (south east of Manhattan) and Staten Island (south west of Manhattan), motorists are more likely to be victims of accidents. In Brooklyn (south of Manhattan), pedestrians are more likely to be the victims of an accident.\n",
    "Using the location data from the data plotted above, the type of victim can be predicted and compared to the actual type of victim shown in the previous map. The predictions made by the KNN classifier described before are shown in the map below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Folium map using NY coordinates\n",
    "pred_map = folium.Map(location=NY_coor, zoom_start = 10)\n",
    "\n",
    "# Create pop ups for types in map\n",
    "pop_ups = ['Pedestrian', 'Cyclist', 'Motorist']\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    # Set location for map as longitude and latitud in X test\n",
    "    loc_X = X_test.loc[i,'LONGITUDE']\n",
    "    loc_Y = X_test.loc[i,'LATITUDE']\n",
    "    \n",
    "    # Use preds to color circle marker\n",
    "    col = pal[1+preds[i]],\n",
    "    \n",
    "    # Create marker as lat lon with color for X_test\n",
    "    folium.Circle(location=[loc_Y, loc_X],\n",
    "      popup=(pop_ups[preds[i]]),\n",
    "      radius = 100,\n",
    "      fill=True,\n",
    "      fill_color=col,         \n",
    "      color = col,\n",
    "      opacity = 0.8, fill_opacity=0.8).add_to(pred_map) \n",
    "    \n",
    "# Add title\n",
    "title_html = titles[1]\n",
    "pred_map.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "# Show maps for predictions\n",
    "pred_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the two maps, the predictions do in fact seem to capture most of the trends observed in the actual data for the victim types, despite the KNN producing an accuracy around 60%. Unlike the map for the actual data, there is a higher concentration of predictions for pedestrians than bicyclists for central Manhattan, but there are still a number of predictions for bicyclists in the area. However, like for the actual data, the likelihood for pedestrians is high around Brooklyn, while for motorists the likelihood is high around Queens and Staten Island. The reason that the KNN is unable to accurately capture the true likelihoods for the victim types can be due to the fact that the dataset is highly unbalanced, the bicycle class being the one with the fewest observations, and the motorist class being the one with the most. This could be solved by balancing the dataset, however balancing the dataset would be biased and would give an incorrect representation of reality, since for example motorists are to a much higher degree involved in accidents than pedestrians and bicyclists.\n",
    "\n",
    "Predicting the most likely victim types for locations in NYC provided information about which areas are most dangerous to specific victims. This can be expanded by including time data, so as to be able to predict the victim type based on the hour of day, month etc. This would allow for making predictions for when and where accident types involving a specific victim type would occur, and resources could be allocated accordingly. It proved to be difficult to accurately classify a victim type based on the latitude and longitude location of the accident. Perhaps by grouping the locations into districts or in a grid-like manner and classifying which victim type is more vulnerable in a given area would provide a model that performs better since it wouldn’t rely on an exact location, but instead, a group of locations that lie on the same area. Furthermore, as was speculated earlier on, weather could have an influence on the accident rates. Future work could include weather information for predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Discussion & Conclusion\n",
    "\n",
    "This project set out to investigate the causes of the continuous increase in traffic accidents and deaths occurring in NYC in recent years despite the fact that Mayor Bill de Blasio in 2014 with his Vision Zero pledged to end traffic related deaths by 2024.  \n",
    "Based on the analysis performed throughout, two main issues were identified. The first being that the infrastructure is likely to be a major contributing factor in the occurring accidents, a lack of bike lanes was seen, immense traffic flow and an indication that the infrastructure was not built to handle such traffic demand. Secondly, it was also seen that the major contributing factors responsible for deaths of pedestrians and cyclists in 2019 were related to careless motorist behaviour such as inattention or distraction, failure to yield, and a disregard to traffic lights. \n",
    "\n",
    "Proposals for solutions for the first of problems regarding infrastructure include altering the infrastructure of NYC by adding dedicated bike lanes. In fact, the city of New York has recently allocated $1.7 billion to changing road infrastructure over the next 10 years, including building more bus, pedestrian, and cyclist space, aspiring to improve safety for cyclists and pedestrians (Bryant, 2019). Based on the analysis conducted in this project, the implementation for the infrastructure could be a great step in the right direction to eliminate traffic related casualties. \n",
    "\n",
    "For the second problem, it seems necessary to make cars a less appealing choice of transportation. There has long been mention of charging NYC drivers to drive at busy hours in the city (Matousek, 2018), however this has yet to unfold. This could motivate more people to make use of other forms of transportation during rush hour and hereby lessen the traffic flow and  prevent accidents from happening during these times. Furthermore, to change the suboptimal behavior of the motorists, efforts could be made into combatting the contributing factors to pedestrian and cyclist deaths, as shown in the beginning of the analysis. Factors such as driver inattention, failure to yield etc. can be difficult to directly combat however, factors such as alcohol and unsafe speed can be regulated with police effort in which more drivers are tested for substance abuse and more speed tickets are issued, as was likewise part of the plan for Vision Zero, or creating more speed bumps, and traffic lights. The latter two rely on changes in the infrastructure, indicating that perhaps, infrastructure and suboptimal driver behavior are related and measures taken in one can improve the other.\n",
    "\n",
    "Implementing these suggestions could help realize the vision of Mayor Bill de Blasio and definitively end all traffic related casualties. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainer Notebook\n",
    "\n",
    "The explainer notebook for this project can be found using [this link](https://nbviewer.jupyter.org/github/Nunukuluk/02806_SDAV/blob/master/Explainer-Notebook.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "ActionKid. (2018, May 18). Lane Splitting an Insane Traffic Jam in New York City [Video]. Youtube. Retrieved May 14, 2020, from https://www.youtube.com/watch?v=0iKFgEPOk20\n",
    "\n",
    "Bryant, M. (2019, November 01). New York City to 'break car culture' and build more than 250 new bike lanes. Retrieved May 14, 2020, from https://www.theguardian.com/us-news/2019/nov/01/new-york-city-bike-lanes-car-culture\n",
    "\n",
    "Current Results. (n.d.). New York City Temperatures: Averages by Month. Retrieved May 14, 2020, from https://www.currentresults.com/Weather/New-York/Places/new-york-city-temperatures-by-month-average.php\n",
    "\n",
    "Fitzsimmons, E. G. (2020, March 10). More Pedestrians and Cyclists are Dying in N.Y.C. Drivers are Often to Blame. Retrieved May 14, 2020, from https://www.nytimes.com/2020/03/10/nyregion/nyc-deaths-pedestrian-cycling.html?fbclid=IwAR1Lk2ATZLGJ2uTDW-VFkPocKruyAjdSb9I7_jg38EAr2b0gQOgaVvDR9Yk\n",
    "\n",
    "Matousek, M. (2018, January 19). Some drivers may be forced to pay up to $25.34 to drive in NYC's busiest areas starting in 2020. Retrieved May 14, 2020, from https://www.businessinsider.com/nyc-drivers-may-have-to-pay-congestion-fee-in-2020-2018-1?r=US\n",
    "\n",
    "NYC OpenData. Motor Vehicle Collissions - Crashes [csv]. (2014, April 28). Retrieved May 14, 2020, from: https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95\n",
    "\n",
    "NYC OpenData. Traffic Volume Counts [csv]. (2018, December 18). Retrieved May 14, 2020, from: https://data.cityofnewyork.us/Transportation/Traffic-Volume-Counts-2014-2018-/ertz-hr4r\n",
    "\n",
    "World Population Review. (2020) Manhattan Population 2020. Retrieved May 14, 2020, from https://worldpopulationreview.com/boroughs/manhattan-population/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
